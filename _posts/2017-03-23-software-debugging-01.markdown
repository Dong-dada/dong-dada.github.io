---
layout: post
title:  "《软件调试》 学习 01 CPU 基础"
date:   2017-03-23 16:35:30 +0800
categories: debugging book-software-debugging
---

* TOC
{:toc}

## 指令和指令集

某一类 CPU 所支持的指令集合被称为指令集(Instruction Set). 根据指令集的特征，可以把 CPU 划分为两大阵营，即 RISC 和 CISC.
- RISC(Reduced Instruction Set Computer, 即精简指令集计算机) 以 ARM 处理器为代表。
- CISC(Complex Instruction Set Computer, 即复杂指令集计算机) 以 x86 处理器为代表。

两者的不同之处主要有：
- RISC 处理器的指令是等长的(通常为 4 个字节)，定长的指令有利于解码和优化，但占用空间比较大。CISC 的指令长度最短 1 个字节，有些长的指令会有几个甚至几十个字节；
- RISC 的指令数量也比较少，ARM 处理器只有两条跳转指令 BLNV 和 BLEQ，而 8086 有 32 条跳转指令。跳转指令对流水线很不利，一旦遇到跳转指令，CPU 就需要做分支预测(branch prediction), 一旦预测失败，就要把已经执行的错误分支结果清理掉，这会降低 CPU 的执行效率。但是丰富的跳转指令为编程提供了很多方便，这是 CISC 处理器的优势；
- RISC 处理器的寻址方式(addressing mode) 相比于 CISC 少了很多种；
- RISC 的通用寄存器数量较多，通常多达 32 个，而 x86 有 8 个通用寄存器：EAX, EBX, ECX, EDX, ESI, EDI, EBP, ESP；
- 从 函数调用 (function/procedure call) 来看，RISC 因为拥有较多的寄存器，通常能够有足够多的寄存器来传递函数参数。而在 CISC 中，即使使用快速调用 (fast call), 也只能将两个参数用寄存器来传递，其他参数仍然要使用寄存器传递。从执行速度来看，使用寄存器执行速度更快。

### 寻址方式

一条指令是由 操作码 + 0 到多个操作数 来构成，寻址方式定义了如何得到操作数，是指令系统乃至 CPU 架构的关键特征。下面以 x86 为例介绍常见的寻址方式：

- 立即寻址(immediate addressing)：操作数直接跟在操作码之后，作为指令的一部分存放在代码段里，比如 `MOV AL,5` 这条指令中，AL(EAX 的低八位) 作为操作目标，5 作为操作数，直接存放在代码段里；
- 寄存器寻址(register addressing): 操作数被预先存放在寄存器中，指令中指定寄存器号，比如 `MOV AX,BX` 这条指令中，操作数被存放在 BX 寄存器中；
- 直接寻址(direct addressing): 操作数的有效地址直接作为指令的一部分跟随在操作码之后，比如 `MOV AX, [402128H]` 这条指令中，操作数的地址 `[402128H]` 跟随在操作码之后；
- 寄存器间接寻址(register indirect addressing): 操作数的地址被预先存放在一个或多个寄存器中，比如 `ADD AX, [BX]` 这条指令中，操作数的地址被存放在 BX 寄存器中；

### CPU 的操作模式

操作模式可以理解为 CPU 的工作方式，在不同的操作模式下 CPU 按照不同的方式来工作，目的是可以执行不同种类的程序、完成不同的任务。迄今为止， IA-32 处理器定义了如下 5 中操作模式：
- 保护模式(Protected Mode): 所有 IA-32 处理器的本位模式，具有强大的虚拟内存支持和完善的任务保护机制，为现代操作系统提供了良好的多任务环境；
- 实地址模式(Real-address Mode): 简称实模式(Real Mode)，即模拟 8086 处理器的工作模式。工作在此模式下的 IA-32 处理器相当于告诉的 8086 处理器。它提供了一种简单的单任务环境，可以直接访问物理内存和 I/O 空间，操作系统和软件运行在同一个内存空间和同一个优先级上。DOS 操作系统运行在实模式下；
- 虚拟 8086 模式(Virtual 8086 Mode): 通过该模式，可以把 8086 程序当做保护模式的一项任务来执行。虚拟 8086 模式允许在不退出保护模式的情况下执行 8086 程序，当 CPU 在执行一个 8086 任务时，它便以类似实模式的方式工作，当 CPU 被切换到其他普通 32 位任务时，仍然以正常的方式工作，这样就可以在一个操作系统下“同时”运行 8086 任务和普通的 32 位任务了。
- 系统管理模式(System Managerment Mode, SMM): 供系统固件执行电源管理、安全检查、或平台相关的特殊任务；
- IA-32e 模式：支持 Inter64 的 64 位工作模式，是 IA-32 CPU 支持 64 位的一种扩展技术，具有对现有 32 位程序的良好兼容性。由两个子模式组成：64 位模式和兼容模式。64 位模式提供了 64 位的线性寻址能力，并且能够访问 64GB 的物理内存。兼容模式用于执行现有的 32 位应用程序。运行在 IA-32e 模式下的 64 位操作系统，系统内核和内核态的驱动程序一定是 64 位的代码，工作在 64 位模式下的应用程序，可以是 64 位也可以是 32 位(将在兼容模式下执行)。


## 寄存器

寄存器(registers) 是位于 CPU 内部的高速存储单元，用来临时存放计算过程中用到的操作数、结果、程序指针或其他信息。CPU 可以直接操作寄存器中的值，因此访问寄存器的速度比访问内存要快得多。

通用寄存器的宽度决定了 CPU 可以直接表示的数据范围。寄存器的宽度和寄存器的个数多少是 CPU 的最基本指标。我们通常说的 CPU 位数，比如 32 位 CPU 或 64 位 CPU, 指的就是 CPU 中通用寄存器的位数。

尽管通用寄存器大多数时候是通用的，但是在某些情况下，它们也有特定的隐含用法。比如 ECX, ESI, EDI 在串循环操作中分别用作计数器、源和目标; EBP 和 ESP 主要用来维护堆栈，ESP(Extended Stack Pointer)通常指向栈顶，EBP(Extended Base Pointer)指向当前栈帧(frame)的起始地址。值得注意的是，在 x86 系统中，栈是向下生长的，因此当栈中压入数据之后，ESP 的数值会减小，而不是增大。

## 理解保护模式

大多数现代操作系统都是多任务的，CPU 的保护模式是现代操作系统实现多任务的基础。

保护模式是为实现多任务而设计的，其名称中的“保护”就是保护多任务环境中各个任务的安全。多任务环境的一个基本问题就是当多个任务同时运行时，如何保证一个任务不会受到其他任务的破坏，同时也不会破坏其他任务。

所谓任务，从 CPU 层看来就是 CPU 可以独立调度和执行的程序单位。从 Windows 操作系统的角度来看，一个任务就是一个线程 Thread.

进一步来说，可以把保护模式对任务的保护机制划分为任务内的保护和任务间的保护。任务内的保护是指同一个任务空间内不同级别的代码不会相互破坏。任务间的保护就是一个任务不会破坏另一个任务。简单说来，任务内的保护是通过特权级别检查来实现的，任务间的保护机制是靠内存映射机制(包括段映射和页映射)来实现的。

### 任务间的保护机制

任务间的保护主要是靠虚拟内存映射机制来实现的，即在保护模式下，每个任务都被置于一个虚拟内存空间中，操作系统决定何时以及如何把这些虚拟内存映射到物理内存。例如在 Win32 下，每个任务都被赋予了 4GB 的虚拟内存空间，尽管不同任务可以访问相同的地址，但因为这个地址仅仅是本任务空间中的虚拟地址，不同任务处于不同的虚拟空间中，不同任务的虚拟地址可以被映射到不同的物理地址，这样就可以很容易防止一个任务内的代码直接访问另一个任务的数据。

IA-32 CPU 提供了两种机制来实现内存映射：段机制(Segmentation) 和 页机制(Paging)。我们之后会对它们进行介绍。

### 任务内的保护机制

任务内保护的目的主要是保护操作系统。

**操作系统的代码和数据通常会被映射到系统中每个任务的内存空间中**，并且对于所有任务其地址是一样的。例如在 Windows 系统中，操作系统的数据和代码通常被映射到每个进程的高 2GB 空间中，这意味着操作系统的空间对于应用程序是“可触及的”，程序中的指针可以访问到操作系统所使用的内存。

任务内保护的核心思想是权限控制，即为代码和数据根据其重要性指定特权级别。高特权的代码可以执行和访问低特权的代码和数据，低特权的代码不可以直接访问高特权的代码和数据。通常操作系统代码是高特权级的，而应用程序的代码是低特权级的，这样一来应用程序虽然可以指向操作系统所在的内存，但不能够访问，一旦访问就会被操作系统发现并禁止。

有时候我们会看到如下的对话框，这就是因为程序访问了高特权级的数据而被系统发现：

![]( {{ site.url }}/asset/software-debugging-access-violation.jpg)

IA-32 处理器定义了 4 个特权级，又称为 Ring, 分别用 0,1,2,3 表示，0 代表特权级最高, 3 代表特权级最低。Windows 操作系统内核运行在 Ring 0, Windows 下的各种程序运行在 Ring3. 因为 Ring0 下运行的通常都是内核模块，所以人们便把在 Ring0 运行说成是在内核模式(Kernel Mode)运行，把在 Ring3 运行说成是在用户模式(User Mode)运行。

处理器通过以下 3 种方式来记录和监控特权级别以实现特权控制：
- 描述符特权级别(Descriptor Privilege Level), 简称 DPL，位于段描述符或门描述符中，用于表示一个段或门(Gate)的特权级别；
- 当前特权级别(Current Privilege Level), 简称 CPL，位于 CS 和 SS 寄存器的位 0 和 位 1 中，用于表示当前正在执行的程序或任务的特权级别。通常 CPL 等于当前正在被执行的代码段的 DPL。当处理器切换到一个不同的 DPL 段时，CPL 会随之变化；
- 请求者特权级别(Requestor Privilege Level), 简称 RPL，用于系统调用的情况，位于保存在栈中的段选择子的位 0 和 位 1，用来代表请求系统服务的应用程序的特权级别。当 CPU 判断是否可以访问一个段时，CPU 既要检查 CPL 也要检查 RPL，这样做的目的是防止高特权级的代码代替应用程序访问应用程序本来没有权限访问的段。举例来说，当应用程序调用操作系统服务时，操作系统会检查保存在栈中的来自应用程序的段选择子的 RPL，确保它与应用程序代码段的特权级别一致。之后，当操作系统再次访问某个段的时候，它会再次检查一次 RPL，如果这时候只检查 CPL 的话，因为正在执行的是操作系统的代码，所以 CPL 反映的不是真正发起访问者的特权级别。

举例说来，当 CPU 要访问位于数据段中的操作数时，会把指向该数据段的段选择子加载到寄存器上，这个时候 CPU 会进行检查，比较 DPL 和当前代码段的 CPL, RPL。只有 CPL, RPL 比 DPL 大于等于时，这个段选择子才能成功加载到寄存器。这样就保证了低特权的代码无法访问高特权的代码或数据。


## 段机制

在之前的介绍中，内存映射的实现需要通过 段机制(Segmentation) 和 页机制(Paging) 来实现。这一节我们对段机制进行介绍。

内存是计算机系统的关键资源，程序必须被加载到内存中才可以被 CPU 执行，程序运行的过程中，也要使用内存来记录数据和动态的信息。IA-32 CPU 提供了多种内存管理机制，这些机制为操作系统实现内存管理功能提供了硬件基础。

CPU 的段机制(Segmentation)提供了一种手段可以将系统的内存空间划分为一个个较小的受保护区域，每个区域称为一个段(Segment)。每个段都有自己的起始地址、边界和访问权限等属性。实现段机制的一个重要数据结构便是段描述符(Segment Descriptor)

### 段描述符

在保护模式下每个内存段都有一个段描述符，这是其他代码访问该段的基本条件。每个段描述符是一个 8 字节长的数据结构，用来描述一个段的位置(基地址，相对于物理内存)、大小、访问控制和状态等信息。具体的字段信息就不介绍了。

### 描述符表

在一个多任务系统中通常会存在多个任务，每个任务又涉及到多个段，每个段都需要一个描述符，因此系统中会存在很多段，为了便于管理，系统用描述符表来存放段描述符。根据用途不同， IA-32 处理器有三种描述符表：全局描述符表 GDT(Global Descriptor Table)、局部描述符表 LDT(Local Descriptor Table) 和中断描述符表 IDT(Interrupt Descriptor Table).

GDT 表是全局的，一个系统通常只有一个 GDT, 供系统中所有程序和任务使用。LDT 是与任务相关的，一个任务可以有一个 LDT，也可以多个任务共享一个 LDT。IDT 表示与 CPU 数量有关的，通常每个 CPU 会建立一个 IDT。

CPU 中内置了三个寄存器 GDTR, IDTR, LDTR 来标识 GDT,IDT,LDT 的位置和边界。其中 LDTR 表示的是当前任务的 LDT 表在 GDT 中的索引。

LDTR 这个寄存器中存的是一个段选择子，段选择子中包含了一个索引，标识了要选择的段在 GDT,LDT 中的位置。通过段选择子去 GDT,LDT 中查询，就能找到对应的段描述符。换句话说段选择子的作用是从表中查询得到段描述符。

归纳一下，段机制使保护模式下的所有任务都在系统分配给它的段空间中执行。每个任务的代码和数据地址都是相对于它所在段的一个段内偏移。处理器根据段选择子在段描述符表中找到对应的段描述符，然后再根据段描述符定位这个段。每个段都有自己的特权级别以实现对代码和数据的保护。


## 分页机制

从 386 开始，IA-32 处理器开始支持分页机制(Paging)。分页机制的主要目的是高效利用内存，按页来组织和管理内存空间，把暂时不用的数据放到外部存储器(通常是硬盘)上。在启用分页机制之后，操作系统将线性地址空间划分为固定大小的页面(4KB, 2MB 或 4MB)。每个页面可以被映射到物理内存或外部存储器上的虚拟内存文件中。

当程序中的指令访问某一地址（虚拟地址）时，CPU 首先会根据段寄存器的内容将虚拟地址转化为线性地址，具体过程是根据段寄存器中的段选择子找到段描述符，然后将段描述符中的基地址加上程序中的偏移地址得到线性地址。接下来，如果 CPU 发现包含该线性地址的内存页不在物理内存上便会产生一个页错误异常(#PF)。该异常的处理程序通常是操作系统的内存管理器例程。内存管理器得到异常报告后会根据异常的状态信息，特别是 CR2 寄存器中包含的线性地址，将所需的内存页加载到物理内存中。然后异常处理例程返回使处理器重新执行导致页错误异常的指令，这时所需的内存页已经在物理内存中，所以便不会再导致页错误异常了。

CPU 和内存管理器使用页目录、页表、页目录指针表 来管理从线性地址到物理地址的映射。

### 页目录(Page Directory)

页目录是用来存放 页目录表项(Page-Directory Entry 简称 PDE) 的线性表，每个页目录表项长度为 32 个比特位(4 字节).

页目录表项指向的是 “页表” 这个数据结构，每个表项都指向了一个页表；

以下是页目录表项的结构：

![]( {{ site.url }}/asset/software-debugging-pde.png)

可以看到每个表项中都存储了 页表基地址、页大小(4KB 或 4MB)、特权级别、读写权限、是否在物理内存中 这些页表的属性。

### 页表(Page Table)

页表是用来存放 页表表项(Page-Table Entry 简称 PTE) 的线性表，每个 PTE 的长度为 32 个比特位(4 字节).

页表表项指向的是 “页” 这个数据结构，每个表项都指向了一个页；

值得注意的是， 2MB, 4MB 这些大内存页是直接存储在页目录里的，而不是存在页表里。页表里存储的只有 4KB 的页；

以下是 页表表项 的结构：

![]( {{ site.url }}/asset/software-debugging-pte.png)

可以看到每个表项中都存储了 页基地址、页大小(4KB 或 4MB)、特权级别、读写权限、是否在物理内存中 这些页表的属性。

对于 4KB 小内存页来说： 页目录 包含 多个页表，每个页表包含 多个页；

对于 2MB, 4MB 大内存页来说，页直接被包含在页目录里面；

### 地址翻译

现在，物理内存被分为了一个一个页，其信息记录在页目录和页表中，我们看看 CPU 如何利用页目录和页表等数据结构来将一个 32 位的虚拟地址翻译为 32 位物理地址的：
1. 通过 CR3 寄存器定位到页目录的起始地址，CR3 寄存器又被称为页目录基地址寄存器(PDBR), 它专门记录页目录的起始地址；
2. 取线性地址的高 10 位作为索引选取页目录的一个表项，也就是 PDE；
3. 根据 PDE 中的页表基地址定位到页表；
4. 取线性地址的 12 到 21 位作为索引选取页表的一个表项，也就是 PTE；
5. 取出 PTE 中的内存页基地址；
6. 取线性地址的低 12 位作为页中偏移与上一步的内存页基地址相加便得到物理地址。

一个虚拟地址(线性地址)被分为了以下三部分：

![]( {{ site.url }}/asset/software-debugging-virtual-address.png)

上面的例子是 4KB 线性地址的分段。它的低 12 位是一个偏移值，大小刚好是 4KB, 它是相对于页基地址的一个偏移值。

通过上述机制，一个虚拟地址 (4KB) 被划分为三个部分，分别为 页基地址偏移值、页索引、页表索引。它可以被映射到 32 位物理内存上，索引 4GB 范围的内存。

当程序执行时，是 CPU 内部的内存管理单元 (Memory Management Unit, MMU) 负责把线性地址转换成物理地址。MMU 需要访问页目录和页表才能完成这项工作，而页目录和页表是存储在内存中的。为了减少翻译地址时访问页表和页目录所造成的开销，CPU 会把最近使用的页表和页目录表项存储在 CPU 内的专用高速缓存中。

值得说明的是，每个页都有一个基地址，这个基地址是相对于物理内存的地址，这个地址是可以随便变的。虚拟地址和物理地址之间并不是一一映射的关系，因为分页机制的存在，只要页的基地址随便变化，映射关系就会发生变化。虚拟地址和物理地址之间是一种乱序的映射。

分页机制的也是虚拟内存技术的基础，当前运行的程序如果需要更多内存，也就需要申请更多的 页. 暂时不用的页可以先存在硬盘上，把物理内存以页的形式转让给需要的程序。 







